# 医学图像处理算法概览

[TOC]

## 1 算法基础

### 1.1 有监督 无监督

​	处理没有标签的数据；eg主成分分析、聚类；reconstruction loss

### 1.2 CNNs

​	共享权重，不同对象的检测器将不是同一个

​	多个卷积层

​	医学应用：there is a preference for far **deeper** models and **stacking** smaller kernels

​	异常检测 the detection of abnormalities

#### 	1.2.1 DNNs（无监督）

​	神经元组成：权重、偏差、非线性函数

​	深度神经网络 = 深度学习

​	代表算法 SAEs DBNs

#### 	1.2.2 CNNs原理补充

​	基本配置：卷积层、Relu层、池化层

​	卷积核：可以区分图像的局部。每个局部选择1个卷积核-即feature

​	**提取特征**：对不同局部进行类似向量的计算，最终在中心取均值——得到feature map（其中的值，越接近为**1**表示对应位置和feature的**匹配越完整**，越是接近**-1**，表示对应位置和feature的**反面匹配**越完整，而值接近**0**的表示对应位置没有任何匹配或者说**没有什么关联**。）

​	非线性激活层：如Relu函数，仅保留正数（舍弃不关联的数据），可减少数据量

​	pooling池化层：还是为了减少数据量。分为Max Pooling、Average Pooling，前者取最大值，平均池化就是取平均值。进一步**提取特征**

​	卷积神经网络特征：**局部连接与参数共享**

​	全连接层 softmax函数：它是一个分类函数，输出的是每个对应类别的概率

​	

​	**卷积**：eg（**索伯滤波器**）是边缘检测器

​	**池化**：相邻像素一般具有相似的值，故存在冗余

​	

​	**卷积层深度**=卷积核个数

#### 	1.2.3 改进：多流结构

​	可以在任何位置进行合并；典型应用 (1) multi-scale image analysis (2) 2.5D classification

​	eg 2.5D可减少大量3D数据，避免完整的3D卷积

### 1.3 U-Net算法

#### 1.3.1 概述

​	**端到端**

​	相对于深度学习，传统机器学习的流程往往由多个独立的模块组成，比如在一个典型的自然语言处理（Natural Language  Processing）问题中，包括分词、词性标注、句法分析、语义分析等多个独立步骤，每个步骤是一个独立的任务，其结果的好坏会影响到下一步骤，从而影响整个训练的结果，这是非端到端的。而深度学习模型在训练过程中，从输入端（输入数据）到输出端会得到一个预测结果，与真实结果相比较会得到一个误差，这个误差会在模型中的每一层传递（反向传播），每一层的表示都会根据这个误差来做调整，直到模型收敛或达到预期的效果才结束，这是端到端的。两者相比，端到端的学习省去了在每一个独立学习任务执行之前所做的数据标注，为样本做标注的代价是昂贵的、易出错的。

​	**上下文**

​	即考虑周边像素，一般没有精准的定义。

​	**介绍**

​	卷积一般为了分类（针对每个像素=确定这个像素的属性，也就是分割）

​	**提出U-Net的本意是将其用于医学图像分割，在以往的CNN中，想将其用于医学图像存在两个困难：**

​	（1）通常CNN都是应用于分类，生物医学图像更关注的是分割以及定位的任务；

​	（2）CNN需要获取大量的训练数据，而医学图像很难获得那么大规模的数据。

​	以往解决上面两点困难的方法是使用滑窗的方法，为每一个待分类的像素点取**周围**的一部分邻域输入。这样的方法有两点好处，首先它完成了定位的工作，其次因为每次取一个像素点周围的邻域，所以大大增加了训练数据的数量。但是这样的方法也有两个缺点，首先通过滑窗所取的块之间具有较大的重叠，所以会导致速度变慢；其次是网络需要在局部准确性和获取上下文之间进行取舍。因为更大的块需要更多的池化层，进而**降低了定位的准确率**，而小的块使网络只看到很小的一部分上下文。

​    **语义分割**

​	语义分割指的是将图像中的每一个像素关联到一个类别标签上的过程。可以认为语义分割是像素级别的图像分类。

#### 1.3.2 FCN结构

​	**上采样**

​	（1）图像缩放，缩-减少像素数目，放-增加像素数目。

​			eg 双线性插值直接缩放。“双”意为二维

​			![clip_image001](https://images0.cnblogs.com/blog/362399/201403/281607508919268.png)

​			已知$Q_{11} Q_{12} Q_{21} Q_{22}$4个点的值，计算$P$点的值。那么先对$R_1$与$R_2$点在x轴方向进行插值，得到$R_1$与$R_2$点的取值后，对$P$计算（y轴方向）

​	（2）Deconvolution，也叫Transposed Convolution。

​			对于一般卷积，输入蓝色4x4矩阵，卷积核大小3x3。当设置卷积参数pad=0，stride=1时，卷积输出绿色2x2矩阵。

​			![img](https://pic2.zhimg.com/v2-705305fee5a050575544c64067405fce_b.webp)

 			而对于反卷积，相当于把普通卷积反过来，输入蓝色2x2矩阵（周围填0变成6x6），卷积核大小还是3x3。当设置反卷积参数pad=0，stride=1时输出绿色4x4矩阵。

​			<img src="https://pic2.zhimg.com/v2-286ac2cfb69abf4d8aa06b8eeb39ced3_b.webp" alt="img" style="zoom:67%;" />

​				传统的网络是subsampling的，对应的输出尺寸会降低；**upsampling的意义在于将小尺寸的高维度feature map恢复回去**，以便做pixelwise prediction，获得每个点的分类信息。

<img src="https://pic3.zhimg.com/80/v2-613b7a2d61f20ff007239e15d6c0c771_720w.jpg" alt="img" style="zoom:80%;" />

​	**FCN原理示意图**

​	<img src="https://pic1.zhimg.com/80/v2-721ef7417b32a5aa4973f1e8dd16d90c_720w.jpg" alt="img" style="zoom:80%;" />

​	

​	**step1  conv**

（1）image经过多个conv和+一个max pooling变为pool1 feature，宽高变为1/2

（2）pool1 feature再经过多个conv+一个max pooling变为pool2 feature，宽高变为1/4

（3）pool2 feature再经过多个conv+一个max pooling变为pool3 feature，宽高变为1/8

（4）...

（5）直到pool5 feature，宽高变为1/32

​	**step2 crop**

（1）对于FCN-32s，直接对poo5 feature进行32倍**上采样**获得32x upsampled feature，再对32x upsampled feature**每个点**做 softmax prediction获得32x upsampled feature prediction（即分割图）.

（2）对于FCN-16s，首先对poo5 feature进行2倍上采样获得2x upsampled feature，再把pool4 feature和2x upsampled feature**逐点相加**，然后对相加的 Feature进行16倍上采样，并softmax prediction，获得16x upsampled feature prediction.

（3）对于FCN-8s，首先进行pool4+2x upsampled feature**逐点相加**，然后又进行pool3+2upsampled逐点相加，即进行更多次特征融合.

（4）...

​	效果如下：FCN-32s < FCN-16s < FCN-8s

​	<img src="https://pic4.zhimg.com/80/v2-8c212e15670c9accca37c57c90f3df7f_720w.jpg" alt="img" style="zoom:67%;" />

#### 1.3.3 U-Net原理

​	U-Net能够适应很小的训练集（大约30张图）

​	<img src="https://pic4.zhimg.com/80/v2-96f5e828c1e83c930aa4a2bb91e64c10_720w.jpg" alt="img" style="zoom:80%;" />

​	（1）conv+pooling下采样

​	（2）Deconv反卷积上采样，crop之前的低层feature map。反复进行

​	（3）直到获得输出388x388x2的feature map，最后经过softmax（**每个像素**）获得output segment map。总体来说与FCN思路非常类似。

#### 	1.3.4 U-Net与FCN的异同

​	U-Net采用了与FCN完全不同的特征融合方式：拼接。

<img src="https://pic1.zhimg.com/80/v2-4e545ee5b0168134c2bf17e3fab25684_720w.jpg" alt="	" style="zoom:80%;" />

​	与FCN逐点相加不同，U-Net采用将特征在channel维度拼接在一起，形成更“厚”的特征。所以：

​	**语义分割网络在特征融合时也有2种办法：**

​	（1）FCN式的**逐点相加**，对应caffe的EltwiseLayer层，对应tensorflow的tf.add()

​	（2）U-Net式的channel维**度拼接融合**，对应caffe的ConcatLayer层，对应tensorflow的tf.concat()

#### 	1.3.5 总结

​	**CNN图像语义分割的基本思路：**

​	（step 1）下采样+上采样：Convlution + Deconvlution／Resize

​	（step 2）多尺度特征融合：特征逐点相加／特征channel维度拼接

​	（step 3）获得像素级别的segement map：对每一个像素点进行判断类别



### 1.4 RNNs算法

​	新增隐藏状态，与input、w、b相关

#### 1.4.1 概述

​	循环神经网络：能够更好的处理**序列**的信息，即前面的输入和后面的输入存在关系。

​	eg 以nlp的一个最简单词性标注任务来说，将我 吃 苹果 三个单词**标注词性**为 我/nn 吃/v 苹果/nn。很明显，一个句子中，前一个单词其实对于当前单词的词性预测是有很大影响的，比如预测苹果的时候，由于前面的吃是一个动词，那么很显然苹果作为名词的概率就会远大于动词的概率，因为动词后面接名词很常见，而动词后面接动词很少见。

#### 1.4.2 RNN结构

​															<img src="https://pic2.zhimg.com/v2-3884f344d71e92d70ec3c44d2795141f_b.jpg" alt="img" style="zoom: 33%;" />

​	**循环神经网络**的**隐藏层**的值S不仅仅取决于当前这次的输入X，还取决于上一次**隐藏层**的值S。**权重矩阵**W就是**隐藏层**上一次的值作为这一次的输入的权重。

​	给出这个抽象图对应的具体图：

<img src="https://pic2.zhimg.com/v2-206db7ba9d32a80ff56b6cc988a62440_b.jpg" alt="img" style="zoom:80%;" />

​	**我们从上图就能够很清楚的看到，上一时刻的隐藏层是如何影响当前时刻的隐藏层的。**

​	如果我们把上面的图展开，**循环神经网络**也可以画成下面这个样子：

<img src="https://pic4.zhimg.com/v2-b0175ebd3419f9a11a3d0d8b00e28675_b.jpg" alt="img" style="zoom:80%;" />

​	现在看上去就比较清楚了，这个网络在t时刻接收到输入![[公式]](https://www.zhihu.com/equation?tex=x_%7Bt%7D) 之后，隐藏层的值是![[公式]](https://www.zhihu.com/equation?tex=s_%7Bt%7D)，输出值是 ![[公式]](https://www.zhihu.com/equation?tex=o_%7Bt%7D) 。关键一点是，![[公式]](https://www.zhihu.com/equation?tex=s_%7Bt%7D)的值不仅仅取决于 ![[公式]](https://www.zhihu.com/equation?tex=x_%7Bt%7D) ，还取决于![[公式]](https://www.zhihu.com/equation?tex=s_%7Bt-1%7D)。我们可以用下面的公式来表示**循环神经网络**的计算方法：

​	**用公式表示如下：**

<img src="https://pic3.zhimg.com/v2-9524a28210c98ed130644eb3c3002087_b.jpg" alt="img" style="zoom: 33%;" />



### 1.5 AEs/SAEs （均无监督）

​	重建input

​	最后通过监督训练对整个神经网络微调

#### 	1.5.1 AEs概述

​	自动编码器(AutoEncoder)是神经网络的一种，一般来讲自动编码器包括两部分：**编码器和解码器**，编码器和解码器相互串联合作，实现数据的**降维或特征学习**，现在也广泛用于**生成模型**中。 在深度学习中，Autoencoder可用于在训练阶段开始前，确定权重矩阵的初始值。

​	自动编码器是一种**无监督**的学习技术，其中我们利用神经网络来完成表示学习的任务。 具体来说，我们将设计一种神经网络体系结构，以使我们在网络中施加一个**bottleneck**，从而迫使对原始输入进行压缩的知识表示。 如果输入特征彼此独立，则这种压缩和随后的重构将是非常困难的任务。 但是，如果数据中存在某种关联（即输入要素之间的相关性），则当通过**bottleneck**强制输入时，可以学习并利用此结构。

​										<img src="https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-06-at-3.17.13-PM.png" alt="Screen-Shot-2018-03-06-at-3.17.13-PM" style="zoom:50%;" />

​	如上图所示，我们可以将未标记的数据集构图为有监督的学习问题，并负责输出$\hat x$（原始输入x的重构）。 可以通过最小化重构误差$L(x,\hat x)$来训练该网络，该误差测量了我们原始输入与后续重构之间的差异。 **bottleneck**是我们网络设计的关键属性。 在没有**bottleneck**的情况下，我们的网络可以轻松地通过将这些值通过网络传递来简单地记住输入值（如下图所示）。

​												<img src="https://www.jeremyjordan.me/content/images/2018/03/Screen-Shot-2018-03-06-at-6.09.05-PM.png" alt="Screen-Shot-2018-03-06-at-6.09.05-PM" style="zoom:50%;" />

​	**bottleneck**限制了可以遍历整个网络的信息量，从而迫使学习的输入数据压缩。

​	注意：实际上，如果构建线性网络（即，在每一层均不使用非线性激活函数的情况下），将观察到与PCA中相似的降维。

​	The ideal autoencoder model balances the following: 

​	（1）Sensitive to the inputs enough to accurately build a reconstruction. 

​	（2）Insensitive enough to the inputs that the model doesn't simply memorize or overfit the training data.

​	对于（1）构造损失函数$L(x,\hat x)$，以训练模型降维后的准确性；同时需要加入正则化惩罚项，以防止（2）的现象。

​																	$$L(x,\hat x)+regularizer$$

​	通常会在正则化项之前添加一个缩放参数，以便可以调整两个目标之间的权衡性。

​	[AEs及相关改进](https://www.jeremyjordan.me/autoencoders/)

#### 	1.5.2 SAEs概述

​	该算法效果比DBN优秀。

​	网络参数的训练方面，AEs采用反向传播法来进行训练，但AEs需要大量的训练样本，随着网络结构越变越复杂，网络计算量也随之增大。

​	堆叠自动编码器方法与DBN相同，具体过程描述如下：（1）给定初始输入，采用无监督方式训练第一层自动编码器，减小重构误差达到设定值。（2）把第一个自动编码器隐含层的输出作为第二个自动编码器的输入，采用以上同样的方法训练自动编码器。（3）重复第二步直到初始化完成所有自动编码器。（4）把最后一个堆叠自动编码器的隐含层的输出作为分类器的输入，然后采用有监督的方法训练分类器的参数。图2给出了含三层AD的堆叠自动编码器的生成过程。

​	<img src="https://pic2.zhimg.com/v2-feb7fffa13f10d9643898237e45bed3f_b.png" alt="img" style="zoom:80%;" />

​	

### 1.6 RBMs（生成模型）/DBNs （均无监督）

​	DBNs are essentially SAEs where the AE layers are replaced by RBMs.

​	此外无监督模型还有VAE、GAN

#### 	1.6.1 RBMs概述

​	受限玻尔兹曼机（RBM，Restricted Boltzmann machine）由多伦多大学的 Geoff Hinton 等人提出，它是一种可以用于**降维、分类、回归、协同过滤、特征学习以及主题建模**的算法。

​	**BM**玻尔兹曼机器是能够学习内部表示的**随机和生成神经**网络，结构如下：

​	<img src="C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200804205235608.png" alt="image-20200804205235608" style="zoom:50%;" />

​	Boltzmann Machine是只有两个类型的节点（**隐藏节点和可见节点**）的非确定性（**随机**）**生成型**深度学习模型。 **没有输出节点**，没有典型的1或0类型输出，无法可通过随机梯度下降来学习和优化模式。

​	玻尔兹曼机在输入节点**之间**具有连接。 从图中可以看出，所有节点都连接到所有其他节点，而不管它们是输入节点还是隐藏节点。 这使它们可以在彼此之间共享信息并自行生成后续数据。 

​	**RBM**也是两层神经网络（一层是可见层，另一层是隐藏层），这两层通过**完全**二部图相连。 这意味着可见层中的每个节点都连接到隐藏层中的**每个**节点，但是**同一组中没有两个节点相互连接**。 这种限制允许使用比一般Boltzmann Machine更有效的训练算法，尤其是**基于梯度的对比发散算法**。

​	<img src="C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200804205825797.png" alt="image-20200804205825797" style="zoom:50%;" />

​	RBM是一个随机神经网络，这意味着每个神经元在激活时都会有一些随机行为。RBM中还有另外两层偏置量（hidden bias and visible bias），这就是使**RBM与自动编码器AE不同**的原因。hidden bias在前向通过时产生激活，visible bias在后向通过时重建输入。重建的输入始终与实际输入不同（一般情况），因为可见层单元之间没有连接，因此无法在它们之间传递信息。

<img src="C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200804211228651.png" alt="image-20200804211228651" style="zoom:67%;" />

​											<img src="C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200804211420955.png" alt="image-20200804211420955" style="zoom:67%;" />

​	现在，差异$v(1)-v(0)$可以看作是我们在训练过程的后续步骤中需要减少的重构误差。因此，在每次迭代中都要调整权重，以最大程度地减少此错误，这就是学习过程的本质。

​	RBM主要通过**概率分布的差异**来衡量重建输入与原始输入之间的差异。

​	其中$p(x)$是原始输入的概率分布，$q(x)$是重建输入的概率分布。**KL散度**测量两个图下的非重叠区域，RBM的优化算法尝试通过更改权重来最小化此差异，以使重建输入与原始输入非常相似。 右侧的图形显示左侧曲线区域差异的积分。

​	<img src="C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200804211822749.png" alt="image-20200804211822749" style="zoom: 67%;" />

​	具体的学习过程需要补充Markov chain Monte Carlo (MCMC) algorithm的相关知识

​	[RBMs](https://towardsdatascience.com/restricted-boltzmann-machines-simplified-eab1e5878976)

##### 	1.6.1.1 Monte Carlo Method

​	![image-20200805125118542](C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200805125118542.png)

​	积分可能难以运算，故基于数值采样近似计算。

​	随机采样的方法：

​	（1）概率分布采样

​	![image-20200805132756654](C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200805132756654.png)

​	（2）Rejection Sampling

​	![image-20200805132827564](C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200805132827564.png)

​	注意概念：未归一化的概率分布

​	原理思想补充：

​	首先举一个简单的例子介绍Monte Carlo方法的思想。假设要估计圆周率$\pi$的值，选取一个边长为1的正方形，在正方形内作一个内切圆，那么可以计算得出，圆的面积与正方形面积之比为$\pi/4$。现在在正方形内随机生成大量的点，如图所示，落在圆形区域内的点标记为红色，在圆形区域之外的点标记为蓝色，那么圆形区域内的点的个数与所有点的个数之比，可以认为近似等于$\pi/4$。因此，Monte Carlo方法是通过随机采样的方式，以频率估计概率。

​	<img src="https://img-blog.csdn.net/20170113132243298?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvanRlbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="img" style="zoom:50%;" />

​	$kq(z)$对应正方形，$\tilde p(z)$对应圆。

​	<img src="https://img-blog.csdn.net/20170117134438602?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvanRlbmc=/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/SouthEast" alt="img" style="zoom:50%;" />

​	（3）Importance Sampling

​	![image-20200805134807131](C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200805134807131.png)

​	即在$q(z)$进行采样，$\frac{p(z_i)}{q(z_i)}$定义为$weight$，$weight$高则抽样效率高，较小的N（采样数）即可得到较好的近似效果。

​	**改进：Sampling-Importance-Resampling：**

​	![image-20200805135244715](C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200805135244715.png)

​	在较高的$weight$上的z采样数也高。

​	（4）Metropolis-Hastings （MH）

​	<img src="C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200805150724472.png" alt="image-20200805150724472" style="zoom:67%;" />

​	该算法与Rejection Sampling不同，不会Rejection。即1000次采样会得到1000个样本，而Rejection Sampling可能仅仅得到600个样本（拒绝了400次）

##### 	1.6.1.2 Markov Chain

​	 随机变量序列。

​	Markov性质：未来只与当前有关![image-20200805140158955](C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200805140158955.png)

​	![image-20200805151602634](C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200805151602634.png)

补充：

<img src="C:\Users\19961\AppData\Roaming\Typora\typora-user-images\image-20200805153301403.png" alt="image-20200805153301403"  /> 

平稳分布关键点：随机变量$x_i$的分布均一样，那么可以构造一个符合平稳分布的Markov Chain来逼近未知分布。其充分不必要条件应用于MH算法。

#### 	1.6.2 DBNs概述

​	也可以堆叠多个RBM，并可以通过梯度下降和反向传播的过程进行微调。 这样的网络称为DBN深度信仰网络。 尽管偶尔会使用RBM，但深度学习社区中的大多数人已开始用通用对抗网络或变体自动编码器代替其使用。

### 1.7 Hardware and software

​	GPUs are highly parallel computing engines, which have an order of magnitude more execution threads than central processing units (CPUs).（10-30 times faster）

## 2 医学图像应用

### 2.1 分类

​	一般单个变量输出

​	transfer learning : (1) using a **pre**-trained network as a feature extractor and (2) fine-tuning a pre-trained network on medical data 前者不需要进一步训练故速度较快，但是2种策略的结果优劣并不一定。

​	**物体/病变分类**

​	关键点：多流架构（eg 多个CNN合并为1个特征向量）；3D，多维度数据

​	The major difference between CSAE and a classic CNN is the usage of unsupervised pre-training with sparse auto-encoders.

### 2.2 定位

​	解析3D数据。eg treat the 3D space as a composition of 2D orthogonal planes.

​	**病变自动定位**

​	class imbalance/hard-negative mining or efficient pixel/voxel-wise processing of images. 

### 2.3 分割

​	RNN在分割中较为流行

​	Xie et al. (2016b) used a spatial clockwork RNN to segment the perimysium in H&E-histopathology images. This network takes into account prior information from both the row and column predecessors of the current patch. To incorporate bidirectional information from both left/top and right/bottom neighbors, the RNN is applied four times in different orientations and the end-result is concatenated and fed to a fully-connected layer. This produces the final output for a single patch.

​	关键词：patch-trained neural networks；fCNNs

### 2.4 spatial alignment

​	eg 评估CT与MRI图像的相似性；leveraged CNNs to perform 3D model to 2D x-ray registration to assess the pose and loca￾tion of an implanted object during surgery

​	常用方法(1) using deep learning networks to estimate a similarity measure for two images to drive an iterative optimization strategy, and (2) to directly predict transformation parameters using deep regression networks.

### 2.5 基于内容的图像检索CBIR

​	关键词：大型数据库；识别相似病例历史；extracting effective feature representations from the pixel-level information and associating them with meaningful concepts；相似性——距离度量

### 2.6 图像生成与增强

​	A variety of image generation and enhancement methods using deep architectures have been proposed, ranging from removing obstructing elements in images, normalizing images, improving image quality, data completion, and pattern discovery.

### 2.7 Combining image data with reports

​	The combination of text reports and medical image data has led to two avenues of research: (1) leveraging reports to improve image classification accuracy (Schlegl et al., 2015), and (2) generating text reports from images.

​	Shin et al. (2015) and Wang et al. (2016e) mined semantic interactions between radiology reports and images from a large data set extracted from a PACS system. They employed latent Dirichlet allocation (LDA), a type of stochastic model that generates a distribution over a vocabulary of topics based on words in a document. 

​	

​	







